{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ded885d-a9d3-4144-9d27-e7610ad5f484",
   "metadata": {},
   "source": [
    "# Operating Differentiation on Variables - with PyTorch Autograd\n",
    "Written on 7/4/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3315e358-4f6c-4e47-9ec7-3c9f684db911",
   "metadata": {},
   "source": [
    "In Nueral Network training, our most prior goal is to find the optimal points in domain which value loss function as minimal. For this goal, we execute differentiation with respect to each input variables on domain. PyTorch Autograd is one of well-known tools for this operation. \n",
    "The `autograd` package offers automatic differentiation for all operations involving Tensors. It operates as running from definition of function itself, meaning that backpropagation is defined by the way your code is defining the function from each variables.\n",
    "\n",
    "Let's understand the Autograd function's principles and observe its tutorials to perform differentiation."
   ]
  },
  {
   "attachments": {
    "7386d96a-7c05-4c30-96ba-fd583178fcef.png": {
     "image/png": "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"
    },
    "baca0238-a2c9-4ed0-9d08-3756a7a00cf7.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "cdadfcb9-b785-46da-bbf0-2c391a41537b",
   "metadata": {},
   "source": [
    "## Preliminary : Initialize Variables to Define Function\n",
    "### Variable\n",
    "The core class of the autograd package is `autograd.Variable`. This class wraps a `Tensor` and supports almost all the operations defined for Tensors. It provides access to the underlying raw tensor via the `.data` attribute, and the gradient with respect to this variable is accumulated in the `.grad` attribute, as illustrated in the following figure.\n",
    "\n",
    "![image.png](attachment:baca0238-a2c9-4ed0-9d08-3756a7a00cf7.png)![image.png](attachment:7386d96a-7c05-4c30-96ba-fd583178fcef.png)\n",
    "\n",
    "The Variable class also includes a *backward* method to perform backpropagation. After computing the function, you can call `.backward()` to automatically calculate all gradients. For instance, to backpropagate a loss function and train model parameter x, you use a variable loss to store the value computed by the loss function. By calling `loss.backward()`, PyTorch computes the gradients ∂loss/∂x for all trainable parameters and stores these gradient results in the corresponding variable x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "572cbbf4-9142-4a6a-8951-d03fc3881c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Variables wrap a Tensor\n",
    "x = Variable(torch.ones(2, 3), requires_grad=True)\n",
    "# Variable containing:\n",
    "# 1  1  1\n",
    "# 1  1  1\n",
    "# [torch.FloatTensor of size 2x3]\n",
    "\n",
    "x.requires_grad = True #requires_grad indicates whether a variable is trainable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f048f0-ec61-47fc-8c46-84d6cb37f93a",
   "metadata": {},
   "source": [
    "### Function\n",
    "\n",
    "Another crucial class for autograd implementation is Function. Variable and Function are interconnected, forming an acyclic graph that encodes the entire history of computation. Each variable has a `.grad_fn` attribute, which references the Function that created the Variable (This is not the Variables the user created, which have a grad_fn of None).\n",
    "\n",
    "To compute derivatives, you can call `.backward()` on a Variable. If the Variable is a scalar which holds a single element, you don't need to provide any arguments to `backward()`. However, if it contains more elements, you must specify a `grad_output` argument, which is a tensor of the same shape.\n",
    "\n",
    "The _backward_ method traverses the graph backward to compute the gradients. After this computation for one iteration, the graph is typically disposed of, although this behavior can be overridden with the `retain_graph` flag (though this is rarely recommended). For the next training iteration, a new graph is created.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52e76e49-694c-4045-b809-4a1a5e8d01a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 6., 6.],\n",
       "        [6., 6., 6.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x * x + 5           # Create y from an operation\n",
    "# [torch.FloatTensor of size 2x3]\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814dde21-3ffc-40e4-870d-dd8e3a696427",
   "metadata": {},
   "source": [
    "## Get Gradient : Use `Autograd` to Differentiate the Variables \n",
    "Now, we can specify the `Autograd` function. There are many options as argument of this PyTorch function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8af53f-a2c2-4ad3-9fb1-868780a9f96a",
   "metadata": {},
   "source": [
    "### Setting `requires_grad`\n",
    "The `requires_grad` flag, which defaults to false unless wrapped in an nn.Parameter, allows for precise exclusion of subgraphs from gradient computation. It affects both the forward and backward passes:\n",
    "\n",
    "- **Forward Pass**: An operation is recorded in the backward graph only if at least one of its input tensors requires gradients.\n",
    "- **Backward Pass**: During the `.backward()` call, only leaf tensors with `requires_grad=True` will have their gradients accumulated in their .grad fields.\n",
    "\n",
    "Although every tensor has this flag, it is meaningful to set it only for leaf tensors (those without a grad_fn e.g. the parameters of an nn.Module). Non-leaf tensors, which do have a grad_fn, are part of a backward graph and thus their gradients are necessary as intermediate results to compute gradients for leaf tensors that require gradients. Consequently, all non-leaf tensors automatically have `requires_grad=True`.\n",
    "\n",
    "The `requires_grad` flag should be the primary method for controlling which parts of the model participate in gradient computation. For instance, to freeze parts of a pretrained model during fine-tuning, apply `.requires_grad_(False)` to the parameters that should not be updated. Since operations involving these parameters won't be recorded in the forward pass, their .grad fields won't be updated during the backward pass, effectively excluding them from the backward graph.\n",
    "\n",
    "Because freezing parts of a model is a common requirement, `requires_grad` can also be set at the module level using `nn.Module.requires_grad_()`. When applied to a module, `.requires_grad_()` affects all of the module's parameters, which have `requires_grad=True` by default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c6585d-50fd-43be-8ce9-2293889c76fa",
   "metadata": {},
   "source": [
    "## Tutorials\n",
    "We will compute gradient of polynomial function by `Autograd` function at given variable values, and compare this with the derivative values computed by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebec184-42fa-47ad-ba3a-90786a381da8",
   "metadata": {},
   "source": [
    "Lets calculate the derivative value of $f(x) = 2x^{3} + 7x + 5$ at $x = 7$ by using `torch.autograd.grad()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a413c1ca-e4a3-428a-bd60-dfddb4cc886e",
   "metadata": {},
   "source": [
    "**Step 1.** Import the torch library and initialize the input value `x` as a tensor and ensure that `requires_grad=True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2fc50a0-66fe-47e7-a340-af0ced345f03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.]], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([[1.0,2.0,3.0],[4.0,5.0,6.0]],requires_grad=True)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8ca639-bb80-442d-a939-47f5f355e520",
   "metadata": {},
   "source": [
    "**Step 2.** Specify the function corresponding to the given mathematical equation $f(x) = 2x^{3} + 5x^{2} + 7x + 10$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e84afee7-f584-44ba-ad6c-e99ad97dd24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 14.,  35.,  80.],\n",
      "        [161., 290., 479.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "\treturn 2*(x**3) + 7*x + 5\n",
    "\n",
    "print(f(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363beb7d-f56e-4791-a111-33b6c4f73e6b",
   "metadata": {},
   "source": [
    "**Step 3.** Let's create a variable `y` that represents the sum of values of $f$ by `f(x).sum()`. This summation process is required since derivative of $f$ at a given domain point can be measured by `torch.autograd.grad(outputs, input)` in which gradient can be implicitly created only for scalar outputs argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3590c904-5ae4-44d3-b4a2-8d51b3d5f0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1059., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = f(x).sum()\n",
    "y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4be084-05a1-429a-adbd-ea1fcc7874c1",
   "metadata": {},
   "source": [
    "**Step 4.** Use `torch.autograd.grad(y, x)` to do derivative operation on f(x) at the given x.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73b47679-8161-45c0-9bb1-72cdd4ebf1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 13.,  31.,  61.],\n",
      "        [103., 157., 223.]]),)\n"
     ]
    }
   ],
   "source": [
    "grad_f = torch.autograd.grad(y, x)\n",
    "print(grad_f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23d8e62-ba56-41ed-8a2e-fc93e61ae400",
   "metadata": {},
   "source": [
    "In other way, we can use `.backward()` function as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cced157b-71f0-4ca9-96d1-ac9981d36314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 13.,  31.,  61.],\n",
      "        [103., 157., 223.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1.0,2.0,3.0],[4.0,5.0,6.0]],requires_grad=True)\n",
    "y = f(x).sum()\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13137c75-8de3-43ad-9827-0617e41a88f4",
   "metadata": {},
   "source": [
    "Without `.sum()` process on $f$ in this `backward` function, we can alternatively take same shape of the loss funciton $f$ as the input variable for this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2197ae7-5797-43c5-9ade-4af37d3f66ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 13.,  31.,  61.],\n",
      "        [103., 157., 223.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1.0,2.0,3.0],[4.0,5.0,6.0]],requires_grad=True)\n",
    "f(x).backward(torch.ones_like(x))\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3efe46-509e-45a7-95be-b4e8911896fd",
   "metadata": {},
   "source": [
    "To crosscheck the derivative of the above steps, let's take derivative on $f$ by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa26ff8a-f48f-4682-9477-b73df7c0b48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 13.,  31.,  61.],\n",
      "        [103., 157., 223.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "df = 6*x**2 + 7\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0491c633-e44c-435c-9c0c-de2079f1544d",
   "metadata": {},
   "source": [
    "As we can see from above that the grad_f value and df are the same.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93edb6de-d829-42a9-9237-8cd3bfc81729",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "[1] https://sebarnold.net/tutorials/beginner/blitz/autograd_tutorial.html <br>\n",
    "[2] https://pytorch.org/docs/stable/notes/autograd.html#locally-disable-grad-doc <br>\n",
    "[3] https://jhui.github.io/2018/02/09/PyTorch-Variables-functionals-and-Autograd <br>\n",
    "[4] https://www.geeksforgeeks.org/how-to-differentiate-a-gradient-in-pytorch <br>\n",
    "[5] https://pytorch.org/docs/stable/generated/torch.autograd.grad.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef432ee-a3b0-4c20-8e32-90884c558ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
